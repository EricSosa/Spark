{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "sc = SparkContext(appName=\"YourTest\", master=\"local[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_tokenize import simple_tokenize\n",
    "from math import log10\n",
    "\n",
    "# Returns a list of tuples with the following format:\n",
    "# ((token1, token2), pmi, co-occurrence_count, token1_count, token2_count)\n",
    "def PMI(threshold):\n",
    "    def pairs(x):\n",
    "        my_list = set(simple_tokenize(x))\n",
    "        pairs = []\n",
    "        for x in my_list:\n",
    "                for y in my_list:\n",
    "                    #skip the pair with the same word\n",
    "                    if x != y:\n",
    "                        pairs.append((x, y))\n",
    "        return pairs\n",
    "    lines = sc.textFile(\"Shakespeare.txt\")\n",
    "    numberlines = lines.count()\n",
    "    tokens = lines.flatMap(lambda x:set(simple_tokenize(x))).map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y)\n",
    "    p = lines.flatMap(lambda x:pairs(x)).map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y)\n",
    "    p = p.filter(lambda x:x[1]>threshold)\n",
    "    p = p.map(lambda x: (x[0][0], x)).join(tokens).map(lambda x: (x[1][0][0][1], x[1])).join(tokens)\n",
    "    p = p.map(lambda x: (x[1][0][0][0], x[1][0][0][1], x[1][0][1], x[1][1]))\n",
    "    pmi = p.map(lambda x:(x[0], log10((x[1]/numberlines)/((x[2]/numberlines)*(x[3]/numberlines))),x[1],x[2],x[3]))\n",
    "    pmi = pmi.sortBy(lambda x:x[1], False)\n",
    "    return pmi.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_tokenize import simple_tokenize\n",
    "from math import log10\n",
    "\n",
    "# Returns a list of samp_size tuples with the following format:\n",
    "# (token, [ list_of_cooccurring_tokens ])\n",
    "# where list_of_cooccurring_tokens is of the form\n",
    "# [((token1, token2), pmi, cooc_count, token1_count, token2_count), ...]\n",
    "def PMI_one_token(threshold, samp_size):\n",
    "    def pairs(x):\n",
    "        my_list = set(simple_tokenize(x))\n",
    "        pairs = []\n",
    "        for x in my_list:\n",
    "                for y in my_list:\n",
    "                    #skip the pair with the same word\n",
    "                    if x != y:\n",
    "                        pairs.append((x, y))\n",
    "        return pairs\n",
    "    lines = sc.textFile(\"Shakespeare.txt\")\n",
    "    numberlines = lines.count()\n",
    "    tokens = lines.flatMap(lambda x:set(simple_tokenize(x))).map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y)\n",
    "    p = lines.flatMap(lambda x:pairs(x)).map(lambda x:(x,1)).reduceByKey(lambda x,y:x+y)\n",
    "    p = p.filter(lambda x:x[1]>threshold)\n",
    "    p = p.map(lambda x: (x[0][0], x)).join(tokens).map(lambda x: (x[1][0][0][1], x[1])).join(tokens)\n",
    "    p = p.map(lambda x: (x[1][0][0][0], x[1][0][0][1], x[1][0][1], x[1][1]))\n",
    "    pmi = p.map(lambda x:(x[0][0],(x[0], log10((x[1]/numberlines)/((x[2]/numberlines)*(x[3]/numberlines))),x[1],x[2],x[3])))\n",
    "    pmi = pmi.groupByKey().cache()\n",
    "    return pmi.map(lambda x:(x[0],list(x[1]))).takeSample(False,samp_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}