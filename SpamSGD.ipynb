{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5NCoc8fsSO"
      },
      "source": [
        "!apt-get update -qq > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnxe-BhPmbBW"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "sc = SparkContext(appName=\"YourTest\", master=\"local[*]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd2wZ_Rji7On"
      },
      "source": [
        "from spamminess import spamminess\n",
        "from math import exp\n",
        "import shutil, os\n",
        "\n",
        "def spark_SGD(training_dataset='spam.train.group_x.txt', output_model='models/group_x_model', delta = 0.002):\n",
        "    def spammi(x):\n",
        "      model = {}\n",
        "      for l in x:\n",
        "        t = l[0]\n",
        "        F = l[1]\n",
        "        score = spamminess(F,model)\n",
        "        prob = 1.0/(1+exp(-score))\n",
        "        for f in F:\n",
        "          if t == 'spam':\n",
        "            if f in model:\n",
        "              model[f] = model[f] + (1.0-prob)*delta\n",
        "            else:\n",
        "              model[f] = (1.0-prob)*delta\n",
        "          elif t == 'ham':\n",
        "            if f in model:\n",
        "              model[f] = model[f] - prob*delta\n",
        "            else:\n",
        "              model[f] = -prob*delta\n",
        "      for (f,w) in model.items():\n",
        "        yield((int(f),w))\n",
        "\n",
        "\n",
        "    if os.path.isdir(output_model):\n",
        "        shutil.rmtree(output_model) # Remove the previous model to create a new one\n",
        "    training_data = sc.textFile(training_dataset)\n",
        "    data = training_data.map(lambda x : x.split(\" \")).map(lambda x:(x[1],x[2:])).coalesce(1)\n",
        "    train = data.mapPartitions(spammi)\n",
        "    train.saveAsTextFile(output_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-DK5bPgi7Oo"
      },
      "source": [
        "def spark_classify(input_model='models/group_x_model', test_dataset='spam.test.qrels.txt', results_path='results/test_qrels'):\n",
        "    if os.path.isdir(results_path):\n",
        "        shutil.rmtree(results_path) # Remove the previous results\n",
        "    test_data = sc.textFile(test_dataset)\n",
        "    d = {}\n",
        "    with open(input_model+\"/part-00000\") as f:\n",
        "      for line in f:\n",
        "        (key, val) = line.strip().strip('()').split(\",\")\n",
        "        d[key] = float(val)\n",
        "    data = test_data.map(lambda x : x.split(\" \")).map(lambda x:(x[0],x[1],x[2:]))\n",
        "    test = data.map(lambda x : (x[0],x[1],spamminess(x[2],d))).map(lambda x : (x[0],x[1],x[2],(\"spam\" if x[2] > 0 else \"ham\")))\n",
        "    test.saveAsTextFile(results_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}