{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "spark = SparkSession.builder.appName(\"YourTest\").master(\"local[2]\").config('spark.ui.port', random.randrange(4000,5000)).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---+--------------------+----+\n",
      "|_c0|       _c1|_c2|                 _c3| _c4|\n",
      "+---+----------+---+--------------------+----+\n",
      "|  0|   ALGERIA|  0| haggle. carefull...|null|\n",
      "|  1| ARGENTINA|  1|al foxes promise ...|null|\n",
      "|  2|    BRAZIL|  1|y alongside of th...|null|\n",
      "|  3|    CANADA|  1|eas hang ironic, ...|null|\n",
      "|  4|     EGYPT|  4|y above the caref...|null|\n",
      "|  5|  ETHIOPIA|  0|ven packages wake...|null|\n",
      "|  6|    FRANCE|  3|refully final req...|null|\n",
      "|  7|   GERMANY|  3|l platelets. regu...|null|\n",
      "|  8|     INDIA|  2|ss excuses cajole...|null|\n",
      "|  9| INDONESIA|  2| slyly express as...|null|\n",
      "| 10|      IRAN|  4|efully alongside ...|null|\n",
      "| 11|      IRAQ|  4|nic deposits boos...|null|\n",
      "| 12|     JAPAN|  2|ously. final, exp...|null|\n",
      "| 13|    JORDAN|  4|ic deposits are b...|null|\n",
      "| 14|     KENYA|  0| pending excuses ...|null|\n",
      "| 15|   MOROCCO|  0|rns. blithely bol...|null|\n",
      "| 16|MOZAMBIQUE|  0|s. ironic, unusua...|null|\n",
      "| 17|      PERU|  1|platelets. blithe...|null|\n",
      "| 18|     CHINA|  2|c dependencies. f...|null|\n",
      "| 19|   ROMANIA|  3|ular asymptotes a...|null|\n",
      "+---+----------+---+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nation_raw = spark.read.csv(\"/nation.tbl\",sep='|',inferSchema=True)\n",
    "nation_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'int'),\n",
       " ('_c1', 'string'),\n",
       " ('_c2', 'int'),\n",
       " ('_c3', 'string'),\n",
       " ('_c4', 'string')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nation_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------+--------------------+\n",
      "|NationKey|      Name|RegionKey|             Comment|\n",
      "+---------+----------+---------+--------------------+\n",
      "|        0|   ALGERIA|        0| haggle. carefull...|\n",
      "|        1| ARGENTINA|        1|al foxes promise ...|\n",
      "|        2|    BRAZIL|        1|y alongside of th...|\n",
      "|        3|    CANADA|        1|eas hang ironic, ...|\n",
      "|        4|     EGYPT|        4|y above the caref...|\n",
      "|        5|  ETHIOPIA|        0|ven packages wake...|\n",
      "|        6|    FRANCE|        3|refully final req...|\n",
      "|        7|   GERMANY|        3|l platelets. regu...|\n",
      "|        8|     INDIA|        2|ss excuses cajole...|\n",
      "|        9| INDONESIA|        2| slyly express as...|\n",
      "|       10|      IRAN|        4|efully alongside ...|\n",
      "|       11|      IRAQ|        4|nic deposits boos...|\n",
      "|       12|     JAPAN|        2|ously. final, exp...|\n",
      "|       13|    JORDAN|        4|ic deposits are b...|\n",
      "|       14|     KENYA|        0| pending excuses ...|\n",
      "|       15|   MOROCCO|        0|rns. blithely bol...|\n",
      "|       16|MOZAMBIQUE|        0|s. ironic, unusua...|\n",
      "|       17|      PERU|        1|platelets. blithe...|\n",
      "|       18|     CHINA|        2|c dependencies. f...|\n",
      "|       19|   ROMANIA|        3|ular asymptotes a...|\n",
      "+---------+----------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nation = nation_raw.toDF('NationKey','Name','RegionKey','Comment','extra').drop('extra').cache()\n",
    "nation.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "tags": [
     "setup",
     "global",
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "def load_dataset_and_set_views(path=\"/\"):\n",
    "    global supplier, orders, customer, partsupp, nation, part\n",
    "    \n",
    "    supplier_raw = spark.read.csv(path+\"supplier.tbl\",sep='|',inferSchema=True).drop(\"_c7\")\n",
    "    supplier = supplier_raw.toDF(\"SuppKey\",\"Name\",\"Address\",\"NationKey\",\"Phone\",\"AcctBal\",\"Comment\").cache()\n",
    "    supplier.createOrReplaceTempView(\"supplier\")\n",
    "    \n",
    "    order_raw = spark.read.csv(path+\"orders.tbl\",sep='|',inferSchema=True).drop(\"_c9\")\n",
    "    orders = order_raw.toDF(\"ORDERKEY\",\"CUSTKEY\",\"ORDERSTATUS\",\n",
    "                            \"TOTALPRICE\",\"ORDERDATE\",\"ORDERPRIORITY\",\n",
    "                            \"CLERK\",\"SHIPPRIORITY\",\"COMMENT\").cache()\n",
    "    orders.createOrReplaceTempView(\"orders\")\n",
    "\n",
    "    customer_raw = spark.read.csv(path+\"customer.tbl\",sep='|',inferSchema=True).drop(\"_c8\")\n",
    "    customer = customer_raw.toDF(\"CUSTKEY\",\"NAME\",\"ADDRESS\",\"NATIONKEY\",\n",
    "                                \"PHONE\",\"ACCTBAL\",\"MKTSEGMENT\",\"COMMENT\").cache()\n",
    "    customer.createOrReplaceTempView(\"customer\")\n",
    "    \n",
    "    partsupp_raw = spark.read.csv(path+\"partsupp.tbl\",sep='|',inferSchema=True).drop(\"_c5\")\n",
    "    partsupp = partsupp_raw.toDF(\"PARTKEY\",\"SUPPKEY\",\n",
    "                                 \"AVAILQTY\",\"SUPPLYCOST\",\"COMMENT\").cache()\n",
    "    partsupp.createOrReplaceTempView(\"partsupp\")\n",
    "    \n",
    "    nation_raw = spark.read.csv(path+\"nation.tbl\",sep='|',inferSchema=True).drop(\"_c4\")\n",
    "    nation = nation_raw.toDF(\"NATIONKEY\",\"NAME\",\"REGIONKEY\",\"COMMENT\").cache()\n",
    "    nation.createOrReplaceTempView(\"nation\")\n",
    "    \n",
    "    part_raw = spark.read.csv(path+\"part.tbl\",sep='|',inferSchema=True).drop(\"_c9\")\n",
    "    part = part_raw.toDF(\"PARTKEY\",\"NAME\",\"MFGR\",\"BRAND\",\"TYPE\",\"SIZE\",\n",
    "                        \"CONTAINER\",\"RETAILPRICE\",\"COMMENT\").cache()\n",
    "    part.createOrReplaceTempView(\"part\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "def five_highest_totalprice_orders_sql():\n",
    "    return spark.sql(\"select ORDERKEY, ORDERDATE, TOTALPRICE from orders ORDER BY TOTALPRICE DESC LIMIT 5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------+\n",
      "|ORDERKEY|          ORDERDATE|TOTALPRICE|\n",
      "+--------+-------------------+----------+\n",
      "|  279812|1994-02-19 00:00:00| 479129.21|\n",
      "|  370726|1996-09-29 00:00:00|  460099.4|\n",
      "|   66659|1993-10-15 00:00:00| 458396.42|\n",
      "|  253639|1998-01-23 00:00:00| 456532.89|\n",
      "|  502886|1994-04-12 00:00:00| 456423.88|\n",
      "+--------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "five_highest_totalprice_orders_sql().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "def five_highest_totalprice_orders_dtf():\n",
    "    return orders.select('ORDERKEY','ORDERDATE','TOTALPRICE').orderBy('TOTALPRICE', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------+\n",
      "|ORDERKEY|          ORDERDATE|TOTALPRICE|\n",
      "+--------+-------------------+----------+\n",
      "|  279812|1994-02-19 00:00:00| 479129.21|\n",
      "|  370726|1996-09-29 00:00:00|  460099.4|\n",
      "|   66659|1993-10-15 00:00:00| 458396.42|\n",
      "|  253639|1998-01-23 00:00:00| 456532.89|\n",
      "|  502886|1994-04-12 00:00:00| 456423.88|\n",
      "+--------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "five_highest_totalprice_orders_dtf().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "def cust_most_recent_order_sql(custkey):\n",
    "    return spark.sql(\"select c.NAME, o.ORDERDATE, o.TOTALPRICE from orders o INNER JOIN CUSTOMER c ON c.CUSTKEY = o.CUSTKEY where o.CUSTKEY={} ORDER BY ORDERDATE DESC LIMIT 1\".format(custkey))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+----------+\n",
      "|              NAME|          ORDERDATE|TOTALPRICE|\n",
      "+------------------+-------------------+----------+\n",
      "|Customer#000000001|1997-03-04 00:00:00| 268835.44|\n",
      "+------------------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_most_recent_order_sql(1).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "def cust_most_recent_order_dtf(custkey):\n",
    "    return orders.filter(\"CUSTKEY = {}\".format(custkey)).join(customer, on=['CUSTKEY'], how='inner').select('NAME','ORDERDATE','TOTALPRICE').orderBy('ORDERDATE', ascending=False).limit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+----------+\n",
      "|              NAME|          ORDERDATE|TOTALPRICE|\n",
      "+------------------+-------------------+----------+\n",
      "|Customer#000000001|1997-03-04 00:00:00| 268835.44|\n",
      "+------------------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_most_recent_order_dtf(1).show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "def distinct_supplied_parts(nname):\n",
    "    return spark.sql(\"\"\"\n",
    "    SELECT COUNT(DISTINCT P.PARTKEY)\n",
    "    FROM partsupp p\n",
    "    INNER JOIN supplier s ON p.SUPPKEY = s.SUPPKEY\n",
    "    INNER JOIN nation n ON s.NATIONKEY = n.NATIONKEY \n",
    "    WHERE n.NAME = '{}'\"\"\".format(nname)).first()[0]\n",
    "    \n",
    "    #DF\n",
    "    #return nation.filter(\"NAME = '{}'\".format(nname)).join(supplier, on=['NATIONKEY'], how='inner').join(partsupp, on=['SUPPKEY'], how='inner').select(\"PARTKEY\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2799"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_supplied_parts(\"CANADA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "def count_suppliers_brand_per_nation(bname):\n",
    "    a = part.filter(\"BRAND = '{}'\".format(bname)).join(partsupp, on=['PARTKEY'], how='inner').select(\"SUPPKEY\").distinct()\n",
    "    b = a.join(supplier, on=['SUPPKEY'], how='inner').select('SUPPKEY','NATIONKEY')\n",
    "    return b.join(nation, on=['NATIONKEY'], how='inner').select('SUPPKEY','NAME').groupBy('NAME').count().orderBy('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      NAME|count|\n",
      "+----------+-----+\n",
      "|   ALGERIA|   34|\n",
      "| ARGENTINA|   38|\n",
      "|    BRAZIL|   41|\n",
      "|    CANADA|   35|\n",
      "|     CHINA|   51|\n",
      "|     EGYPT|   39|\n",
      "|  ETHIOPIA|   32|\n",
      "|    FRANCE|   35|\n",
      "|   GERMANY|   49|\n",
      "|     INDIA|   45|\n",
      "| INDONESIA|   45|\n",
      "|      IRAN|   39|\n",
      "|      IRAQ|   40|\n",
      "|     JAPAN|   40|\n",
      "|    JORDAN|   28|\n",
      "|     KENYA|   35|\n",
      "|   MOROCCO|   40|\n",
      "|MOZAMBIQUE|   32|\n",
      "|      PERU|   37|\n",
      "|   ROMANIA|   32|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_suppliers_brand_per_nation(\"Brand#14\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "def order_number_per_customer_nation(nname):\n",
    "    a = nation.filter(\"NAME = '{}'\".format(nname)).join(customer, on=['NATIONKEY'], how='inner').select(\"CUSTKEY\")\n",
    "    b = a.join(orders, on=['CUSTKEY'], how='inner').select(year(\"ORDERDATE\").alias('year')).groupBy('year').count().orderBy('count', ascending=False)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year|count|\n",
      "+----+-----+\n",
      "|1992|  982|\n",
      "|1996|  940|\n",
      "|1995|  932|\n",
      "|1997|  921|\n",
      "|1994|  912|\n",
      "|1993|  900|\n",
      "|1998|  595|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "order_number_per_customer_nation(\"CANADA\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}